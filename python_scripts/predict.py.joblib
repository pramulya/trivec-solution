import sys
import os

# FORCE PATH: Ensure user site-packages are visible if needed
sys.path.append(r"C:\Users\denni\AppData\Roaming\Python\Python313\site-packages")
# Add local project libs
sys.path.append(os.path.join(os.path.dirname(__file__), "pylib"))

import json
import argparse
import joblib
import pandas as pd
import re
import traceback

# ------------------------------------------------------------------------
# Feature Extraction Logic (Must match Model V2 training exactly)
# ------------------------------------------------------------------------
URL_RE = re.compile(r"http[s]?://", re.IGNORECASE)
EMAIL_RE = re.compile(r"\b[\w\.-]+@[\w\.-]+\.\w+\b", re.IGNORECASE)
DIGIT_SEQ_RE = re.compile(r"\d{9,}")

def has_url(t): return 1 if URL_RE.search(str(t)) else 0
def has_email(t): return 1 if EMAIL_RE.search(str(t)) else 0
def has_phone(t):
    s = re.sub(r"[^\d]", "", str(t))
    return 1 if DIGIT_SEQ_RE.search(s) else 0

def get_text_col(df_in, col_name):
    """
    Helper for joblib to reconstruct the pipeline.
    Must match definition in Model V2.py exactly.
    """
    return df_in[col_name]

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", required=True, help="Path to .joblib model bundle")
    parser.add_argument("--input-file", help="Path to JSON input file (optional, defaults to stdin)")
    args = parser.parse_args()

    # 1. Read JSON Input
    try:
        raw_input = ""
        if args.input_file:
            # Try multiple encodings for file input
            for enc in ['utf-8', 'utf-16', 'latin-1']:
                try:
                    with open(args.input_file, 'r', encoding=enc) as f:
                        raw_input = f.read()
                    break
                except UnicodeError:
                    continue
        else:
            # Read from STDIN
            import io
            sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
            raw_input = sys.stdin.read()

        if not raw_input:
            print("[]")
            return
        
        data = json.loads(raw_input)
    except Exception as e:
        print(json.dumps({"error": "Invalid JSON input", "details": str(e)}))
        sys.exit(1)

    if not isinstance(data, list):
        print(json.dumps({"error": "Input must be a JSON list of objects"}))
        sys.exit(1)

    if len(data) == 0:
        print("[]")
        return

    # 2. Convert to DataFrame
    df = pd.DataFrame(data)
    
    # Standardize text column: App sends 'body', Model expects what it was trained with.
    if 'body' not in df.columns:
         print(json.dumps({"error": "Input JSON objects must have 'body' field"}))
         sys.exit(1)

    # 3. Load Model Bundle
    try:
        bundle = joblib.load(args.model)
        model = bundle["model"]
        threshold = bundle["threshold"]
        use_meta = bundle.get("use_meta", 0)
        text_col = bundle.get("text_col", "message")
    except Exception as e:
        print(json.dumps({"error": "Failed to load model bundle", "details": str(e)}))
        sys.exit(1)

    # 4. Prepare Features
    try:
        # Create the specific text column the model expects
        df[text_col] = df['body'].astype(str).fillna("")

        if use_meta == 1:
            df["has_url"] = df['body'].apply(has_url)
            df["has_email"] = df['body'].apply(has_email)
            df["has_phone"] = df['body'].apply(has_phone)
            
            # Select columns strictly
            X = df[[text_col, "has_url", "has_email", "has_phone"]]
        else:
            X = df[[text_col]]

        # 5. Predict
        # predict_proba returns [[prob_0, prob_1], ...]
        probs = model.predict_proba(X)[:, 1]
        
    except Exception as e:
        print(json.dumps({"error": "Prediction failed", "details": str(e), "traceback": traceback.format_exc()}))
        sys.exit(1)

    # 6. Format Output
    results = []
    for idx, row in df.iterrows():
        prob = float(probs[idx])
        score_percent = round(prob * 100, 2)
        
        # Decision based on the bundle's optimal threshold
        is_phishing = 1 if prob >= threshold else 0
        
        # Label logic
        label = "phishing" if is_phishing else "safe"
        
        # Add 'suspicious' logic: if it's close to the threshold or in a "gray zone"
        # Let's say: if it's NOT phishing (below threshold) but above 50%, or
        # if it IS phishing but barely (e.g. within 10% of threshold).
        # For simplicity, let's keep the user's existing "suspicious" logic if desired,
        # or stick to the strict model threshold.
        # Strict logic:
        # label = "phishing" if prob >= threshold else "safe"
        
        # Hybrid logic for UI readiness:
        if 0.50 <= prob < threshold:
             label = "suspicious"
        elif prob >= threshold:
             label = "phishing"
        else:
             label = "safe"

        results.append({
            "id": row.get('id'),
            "score": score_percent,
            "label": label,
            "threshold_used": threshold
        })

    print(json.dumps(results))

if __name__ == "__main__":
    main()
